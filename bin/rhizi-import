#!/usr/bin/env python
# -*- coding: utf-8 -*-

import re
import os
import argparse

import yaml
import pandas

from rhizi_client import RhiziAPIClient, set_debugging


try:
    unicode
except:
    unicode = str


verbose = False


def verbose_print(s):
    if verbose:
        debug_print(s)


def parse_data(filename, header=None):
    """Parse CSV data from file"""
    if header is None:
        header = [0, 1]
    df = pandas.read_csv(filename, dtype=str, na_filter=False,
                         header=header, encoding='utf-8')

    verbose_print("Data: {} rows to export".format(len(df)))
    return df


uppercase = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
assert len(uppercase) == 26


def index_to_alphabet(ind):
    """
    A..Z - 1..26 - 0..25
    A(A..Z) - 27..52 - 26..51
    """
    assert ind >= 1
    ind -= 1
    ret = []
    while True:
        rem = ind % 26
        ret.append(chr(ord('A') + rem))
        ind = (ind // 26) - 1
        if ind < 0:
            break
    return ''.join(reversed(ret))


def test_conversion():
    for i in range(1, 1000):
        al = index_to_alphabet(i)
        i2 = alphabet_to_index(al)
        assert(i == i2)


def alphabet_to_index(al):
    assert set(al) <= set(uppercase)
    ret = 0
    for c in al:
        ret = ret * 26 + (1 + ord(c) - ord('A'))
    return ret


uppercase_and_plus = set(uppercase + '+')
uppercase_and_minus = set(uppercase + '-')
uppsercase_and_plusminus = set(uppercase + '+-')


def tokens(s, separators=None):
    if separators is not None:
        last = separators[-1]
        for one in separators[:-1]:
            s = s.replace(one, last)
    else:
        last = None
    return [x.strip() for x in s.split(last)]


def sum_expr_to_indices(expr):
    return expr_to_indices(expr, '+')

def expr_to_indices(expr, separators):
    return [alphabet_to_index(x.strip()) for x in tokens(expr, separators)]


class InvalidRuleApplication(Exception):
    """
    Could not apply rule to row

    TODO: add row and rule as parameters to exception
    """


class OutofBoundsIndex(InvalidRuleApplication):
    pass


class ValueIsNan(InvalidRuleApplication):
    pass


def array_of_kv_dicts_to_dict(ar):
    ret = {}
    for d in ar:
        assert len(d) == 1
        ret.update(d) # TODO: translate key names ('type' -> ??)
    return ret


def parse_node_rule(rule):
    """
    {'node': [{'type': 'person'},
    {'name': 'B + A'},  ---or repeater--- {'name': 'Q-Z'}
    {'work address': 'X + Y + Z + AA + AB'},
    {'subtype-tags': 'Phd student 2015'}]}

    We implement a slightly more general csv to graph language, wherein you can
    sum columns from the same row as much as you want
    """
    attrs_factory = array_of_kv_dicts_to_dict(rule)

    repeater = None
    repeater_key = None
    name_indices = None
    for k, v in attrs_factory.items():
        verbose_print("going over {}, {}".format(repr(k), repr(v)))
        # TODO: use a robust way instead of relying on upper case and + sign
        s = set(v) - {' '}

        if s <= uppercase_and_plus:
            indices = sum_expr_to_indices(v)
            if any(i > 26**2 for i in indices):
                debug_print("suspect rule - index {} > {}".format(i, 26**2))

            def get_value(row, indices=indices):
                if any(i > len(row) for i in indices):
                    raise OutofBoundsIndex("{}; {}".format(str(indices), len(row)))
                ret = u' '.join(unicode(row[i]) for i in indices if row[i] != '')
                verbose_print("get_value: {}, {!r} => {}".format(row, indices, ret))
                return ret

            get_value.indices = indices
            if k == 'name':
                verbose_print("reading name indices {}".format(indices))
                name_indices = indices
            attrs_factory[k] = get_value

        elif s <= uppercase_and_minus and s >= {'-'}:
            assert repeater is None
            assert len([x for x in v if x == '-']) == 1
            indices = [alphabet_to_index(x.strip()) for x in tokens(v, '-')]
            assert len(indices) == 2
            def gen_changed_attr(row, df, start=indices[0], end=indices[1] + 1, key=k):
                for i in range(start, end):
                    yield i, {key: row[i]}
            repeater = gen_changed_attr
            repeater_key = k
            def just_to_store_the_indices(row, v=v):
                return v
            just_to_store_the_indices.indices = indices
            attrs_factory[k] = just_to_store_the_indices

        elif k == 'name':
            # must be a field added via preprocess, store it as such
            def preprocessed_split_row_lookup(row, df, split_key=v, key=k):
                orig_col = df.col_to_index[split_key]
                for i, v in enumerate(row[orig_col]):
                    yield (orig_col, i), {key: v}
            repeater = preprocessed_split_row_lookup
            repeater_key = k
            def just_to_store_the_indices(row, v=v):
                return v
            just_to_store_the_indices.indices = v
            attrs_factory[k] = just_to_store_the_indices

    # we assume all names are variably created or we are using a repeater for
    # name
    if repeater:
        name_indices = None
        assert repeater_key == 'name' and callable(attrs_factory['name'])
    else:
        assert callable(attrs_factory['name']) and hasattr(attrs_factory['name'], 'indices')

    def action_one(graph, rzdoc_name, row, df, name_indices=name_indices, more_attrs=None):
        attrs_pre = dict(attrs_factory)
        if more_attrs is not None:
            attrs_pre.update(more_attrs)
        # pass one - run callables
        attrs = {}
        for k, v in attrs_pre.items():
            new_v = v(row) if callable(v) else v
            verbose_print("pre: {} => {}".format(k, new_v))
            attrs[k] = new_v
        # pass two - use formating
        for k, v in attrs.items():
            if unicode(v) == u'nan':
                if k == 'name':
                    verbose_print("skipping all node since name is nan") # TODO print more debugging/validation information - what rule produced this, which row index / complete row
                    return
                debug_print("skipping key {} since it's value is nan".format(k))
                continue
            attrs[k] = unicode(v).format(**attrs)
        node_id = graph.get_id()
        sorted_name_indices = tuple(sorted(name_indices))
        graph.node_create_one(rzdoc_name=rzdoc_name,
                              name=attrs['name'],
                              node_id=node_id,
                              labels=[attrs['type']],
                              sorted_name_indices=sorted_name_indices,
                              attrs=attrs) # TODO - check this against existing graph

    if repeater:
        def action(graph, rzdoc_name, row, df):
            for i, more_attrs in repeater(row=row, df=df):
                action_one(graph=graph, df=df, rzdoc_name=rzdoc_name, row=row,
                           name_indices=[i], more_attrs=more_attrs)
    else:
        action = action_one
    action.attrs_factory = attrs_factory
    action.rule = rule
    return action


edge_regexp = re.compile('^\[([A-Z+-]*)\]\s*([^\[]+)\s*\[([A-Za-z+-]*)\]$')


class RowLocation(object):
    pass


class RowIndices(RowLocation):
    """
    Represents a collection of subsets of whole columns
    """
    def __init__(self, indices):
        self.indices = indices

    def __call__(self, df, row):
        return iter(self.indices)


class RowStar(RowLocation):
    """
    Represents a collection of subsets of a single column,
    generally a column containing a list.
    """
    def __init__(self, col_name):
        self.col_name = col_name

    def __call__(self, df, row):
        col_index = df.col_to_index[self.col_name]
        val = row[col_index]
        return [((col_index, i),) for i in range(len(val))]


def edge_expr_to_index_list(expr):
    # HACK: should have AST at this point. Instead we parse and give meaning
    # in the same place (language, language).
    if expr.upper() != expr: # has lower case => is a preprocess created name
        ret = RowStar(expr)
    elif '-' in expr:
        assert expr.count('-') == 1
        assert '+' not in expr
        assert set(expr) <= set(uppercase_and_minus)
        start, end = expr_to_indices(expr, separators='-')
        index_list = [(i,) for i in range(start, end + 1)]
        ret = RowIndices(index_list)
    else:
        index_list = [expr_to_indices(expr, separators='+')]
        ret = RowIndices(index_list)
    return ret


def debug_print(s):
    print('RZIMP: {}'.format(s))


def parse_edges_rules(rules):
    " [A+B] worked on [C] "
    ret = []
    for data in rules:
        A_expr, label, B_expr = edge_regexp.match(data).groups()
        label = label.strip()
        A_indices_list = edge_expr_to_index_list(A_expr)
        B_indices_list = edge_expr_to_index_list(B_expr)
        def action(graph, rzdoc_name, row, df,
                   A_indices_list=A_indices_list,
                   B_indices_list=B_indices_list,
                   label=label):
            for A_indices in A_indices_list(df=df, row=row):
                nodeA_id = graph.id_from_indices(A_indices)
                if nodeA_id is None:
                    debug_print(u"skipping edge, missing node based on {}, values {}".format(
                        A_indices, u','.join(u"{}".format(row[i]) for i in A_indices)))
                    continue
                for B_indices in B_indices_list(df=df, row=row):
                    nodeB_id = graph.id_from_indices(B_indices)
                    if nodeB_id is None:
                        debug_print(u"skipping edge, missing node based on {}, values {}".format(
                            B_indices, u','.join(u"{}".format(row[i]) for i in B_indices)))
                        continue
                    debug_print("{}: creating edge {} -- [{}] --> {}".format(
                        rzdoc_name, nodeA_id, label, nodeB_id))
                    graph.edge_create_one(rzdoc_name=rzdoc_name, nodeA_id=nodeA_id,
                                        nodeB_id=nodeB_id, relationships=[label])
        action.rule = data
        ret.append(action)
    return ret


class PreprocessRule(object):
    def __init__(self, source, target):
        self.source = source
        self.target = target

    def action(self, df):
        source_index = alphabet_to_index(self.source) - 1
        col_num = len(df.columns)
        df[self.target] = [[s.strip() for s in x.split(',')] for x in df.iloc[:, source_index]]
        assert df.columns[col_num] == self.target or self.target in df.columns[col_num] # no idea how to get the index directly, so assert that it behaves as we expect
        if not hasattr(df, 'col_to_index'):
            df.col_to_index = {}
        df.col_to_index[self.target] = col_num + 1 # index is col 0, the rest are based on 0
        return df


def parse_preprocess_rule(yaml):
    d = array_of_kv_dicts_to_dict(yaml)
    # only support a single action: split to create a new field
    assert 'target' in d
    assert 'source' in d
    assert d['action'] == 'split'
    assert d['params'] == 'comma'
    rule = PreprocessRule(source=d['source'], target=d['target'])
    return rule


def preprocess(data, rules):
    for rule in rules:
        data = rule.action(data)
    return data


def parse_rules(filename):
    with open(filename) as fd:
        _rules = yaml.load(fd)
    rules = []
    prerules = []
    for rule in _rules:
        if 'node' in rule:
            rules.append(parse_node_rule(rule['node']))
        elif 'edges' in rule:
            rules.extend(parse_edges_rules(rule['edges']))
        elif 'preprocess' in rule:
            prerules.append(parse_preprocess_rule(rule['preprocess']))
    return lambda data: preprocess(data, prerules), rules


class GraphBuilder(object):

    def __init__(self, api):
        self.next_id = 0
        self.name_ind_to_id = {} # (1, 2) -> 10
        self.node_id_to_name = {}
        self.api = api

    def new_row(self):
        self.name_ind_to_id.clear()

    def get_id(self):
        ret = self.next_id
        self.next_id += 1
        return str(ret)

    def _record(self, node_id, sorted_name_indices):
        assert sorted_name_indices not in self.name_ind_to_id
        assert tuple(sorted(sorted_name_indices)) == sorted_name_indices
        self.name_ind_to_id[sorted_name_indices] = node_id

    def edge_create_one(self, rzdoc_name, nodeA_id, nodeB_id, relationships):
        if self.node_id_to_name[nodeA_id] == '':
            verbose_print('skipping edge because nodeA_id = {} name is empty'.format(nodeA_id))
            return
        if self.node_id_to_name[nodeB_id] == '':
            verbose_print('skipping edge because nodeB_id = {} name is empty'.format(nodeB_id))
            return
        self.api.edge_create_one(rzdoc_name=rzdoc_name, nodeA_id=nodeA_id, nodeB_id=nodeB_id, relationships=relationships)

    def node_create_one(self, rzdoc_name, name, node_id, labels, sorted_name_indices, attrs):
        if len(name.strip()) == 0:
            print("not creating a zero length name node (sorted_name_indices = {}, attrs = {})".format(sorted_name_indices, attrs))
            return
        debug_print("{}: creating node id={} attrs={!r}".format(rzdoc_name, node_id, attrs))
        self._record(node_id=node_id, sorted_name_indices=sorted_name_indices)
        self.node_id_to_name[node_id] = name
        self.api.node_create_one(rzdoc_name=rzdoc_name, name=name, node_id=node_id,
                                 labels=labels) # TODO - check this against existing graph
        self.api.node_update_attr_single(rzdoc_name=rzdoc_name, node_id=node_id, attrs=attrs)

    def id_from_indices(self, indices):
        return self.name_ind_to_id.get(tuple(sorted(indices)), None)


def main():
    global verbose

    # cli parser
    parser = argparse.ArgumentParser(description='Rhizi Importer with simples options')
    parser.add_argument('filename', action="store", default=None, help='CSV file path' )
    parser.add_argument('--base-url', default='http://localhost:8080', help='Base URL for the API')
    parser.add_argument('--user', default=None, help='Username')
    parser.add_argument('--password', default=None, help='Password' )
    parser.add_argument('--rz-doc-name', type=unicode, default="Welcome to Rhizi", help='Name of the document to update' )
    parser.add_argument('--verbose', default=False, help='Show / hide logs' )
    parser.add_argument('--rules', help='yaml file with rules to create graph from csv')
    parser.add_argument('--header', help='list of columns to use for header rows', default='0,1')

    args = parser.parse_args()

    # verbose mode


    # init Client API
    verbose = args.verbose
    verbose_print(args.base_url)
    client = RhiziAPIClient(args.base_url, args.user, args.password, debug=args.verbose)

    #check if the file exists
    if not os.path.isfile(args.filename):
        raise ValueError("File '%s' doesn't exist" % args.filename)

    # parse data
    header = [int(x.strip()) for x in args.header.split(',')]
    if len(header) == 1:
        header = header[0]
    data = parse_data(args.filename, header)

    preprocess, rules = parse_rules(args.rules)

    data = preprocess(data)

    graph = GraphBuilder(client)

    for row_i, row in enumerate(data.itertuples()):
        graph.new_row()
        for r_i, rule in enumerate(rules):
            rule(graph=graph, rzdoc_name=args.rz_doc_name, df=data, row=row)


if __name__ == '__main__':
    main()
